{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSAI HW2-BooleanSearch\n",
    "- 使用Cache的策略\n",
    "    1. 每個operand第一次被搜尋到時使用循序搜尋，並將該operand與對應搜尋到的index以字典形式儲存到Cache中\n",
    "    2. 當operand第二次以上被搜尋到時則可使用已Cache起來的index資訊以減少搜尋量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Cache:\n",
    "    def __init__(self):\n",
    "        self.index_dic = {}\n",
    "\n",
    "    def cache_op_index(self,op,index):\n",
    "        if op not in self.index_dic:\n",
    "            self.index_dic[op] = []\n",
    "            self.index_dic[op].append(index)\n",
    "        else:\n",
    "            self.index_dic[op].append(index)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # You should not modify this part.\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--source',\n",
    "                       default='source.csv',\n",
    "                       help='input source data file name')\n",
    "    parser.add_argument('--query',\n",
    "                        default='query.txt',\n",
    "                        help='query file name')\n",
    "    parser.add_argument('--output',\n",
    "                        default='output.txt',\n",
    "                        help='output file name')\n",
    "    parser.add_argument('-f',\n",
    "                        default=None,\n",
    "                        help='')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Please implement your algorithm below\n",
    "    \n",
    "    # TODO load source data, build search engine\n",
    "    source = pd.read_csv(args.source,names = [\"index\",\"title\"]).values\n",
    "\n",
    "    with open (args.query,\"r\",encoding = \"UTF - 8\") as q_f:\n",
    "        queries = q_f.readlines()\n",
    "        index_list = []\n",
    "        \n",
    "        cache = Cache()\n",
    "        pre_index = cache.index_dic \n",
    "        \n",
    "    # TODO compute query result\n",
    "        for q_line in queries:\n",
    "            query = q_line.split()\n",
    "            operator = query[1]\n",
    "            operands = query[::2]\n",
    "\n",
    "            if(operator == \"and\"):\n",
    "                and_result=[]\n",
    "                in_pre_index = False\n",
    "                all_in_pre_index = True\n",
    "                less_index_op = operands[0]\n",
    "                \n",
    "                for op in operands:\n",
    "                    if(op in pre_index):\n",
    "                        in_pre_index = True\n",
    "                        base_op = op\n",
    "                    else:\n",
    "                        all_in_pre_index = False\n",
    "\n",
    "                if(all_in_pre_index):\n",
    "                    and_result = pre_index[operands[0]]\n",
    "                    for op in operands:\n",
    "                        and_result = list(set(and_result) & set(pre_index[op]) )\n",
    "                    and_result.sort()\n",
    "                    and_result=[str(x) for x in and_result]\n",
    "                    \n",
    "                elif(in_pre_index):\n",
    "                    for cached_index in pre_index[base_op]:\n",
    "                        for op in operands:\n",
    "                            find_and = True\n",
    "                            find = source[cached_index-1][1].find(op)\n",
    "                            if(find<0):\n",
    "                                find_and = False\n",
    "                                break\n",
    "                        if(find_and):\n",
    "                            and_result.append(str(cached_index))\n",
    "                else:\n",
    "                    for title in source:\n",
    "                        find_and = True\n",
    "                        for op in operands:\n",
    "                            find = title[1].find(op)\n",
    "                            if(find>=0):\n",
    "                                cache.cache_op_index(op,title[0])\n",
    "                            else:\n",
    "                                find_and = False\n",
    "                        if(find_and):\n",
    "                            and_result.append(str(title[0]) )\n",
    "                    \n",
    "                if(len(and_result)==0):\n",
    "                    and_result.append(\"0\")\n",
    "                \n",
    "                and_result_str = ','.join(and_result)\n",
    "                index_list.append(and_result_str)\n",
    "                \n",
    "            elif(operator == \"or\"):\n",
    "                or_result = []\n",
    "                in_cache_op = []\n",
    "                out_op = []\n",
    "                for op in operands:\n",
    "                    if op in pre_index:\n",
    "                        in_cache_op.append(op)\n",
    "                    else:\n",
    "                        out_op.append(op)\n",
    "                for op in out_op:\n",
    "                    for title in source:\n",
    "                        find = title[1].find(op)\n",
    "                        if(find>=0):\n",
    "                            or_result.append(title[0])\n",
    "                            cache.cache_op_index(op,title[0])\n",
    "                or_result = list(set(or_result))\n",
    "                \n",
    "                for op in in_cache_op:\n",
    "                    or_result = list( set(or_result) | set(pre_index[op]) )\n",
    "\n",
    "                if(len(or_result)==0):\n",
    "                    or_result.append(0)  \n",
    "                \n",
    "                or_result.sort()\n",
    "                or_result=[str(x) for x in or_result]\n",
    "                or_result_str = ','.join(or_result)\n",
    "                index_list.append(or_result_str)\n",
    "\n",
    "            elif(operator == \"not\"):\n",
    "                not_result = []\n",
    "                if(operands[0] in pre_index):\n",
    "                    not_result = pre_index[operands[0]]\n",
    "                    for not_op in operands[1:]:\n",
    "                        if(not_op in pre_index):\n",
    "                            not_result = list(set(not_result) - set(pre_index[not_op]))\n",
    "                        else:\n",
    "                            not_list = []\n",
    "                            for base_index in pre_index[operands[0]]:\n",
    "                                find = source[base_index-1][1].find(not_op)\n",
    "                                if(find>=0):\n",
    "                                    not_list.append(base_index)\n",
    "                            not_result = list(set(not_result) - set(not_list) )\n",
    "                else:\n",
    "                    not_result = [ ]\n",
    "                    for title in source:\n",
    "                        find_not = False\n",
    "                        find_first = title[1].find(operands[0])\n",
    "                        if(find_first>=0):\n",
    "                            cache.cache_op_index(operands[0],title[0])\n",
    "                            for n_op in operands[1:]:\n",
    "                                find_n_op = title[1].find(n_op)\n",
    "                                if(find_n_op>=0):\n",
    "                                    find_not = True\n",
    "                                    break \n",
    "                            if(find_not==False):\n",
    "                                not_result.append( title[0] )\n",
    "                        \n",
    "                    if(len(not_result)==0):\n",
    "                        not_result.append(0)           \n",
    "                \n",
    "                if(operands[0] in pre_index):\n",
    "                    not_result.sort()\n",
    "                not_result=[str(x) for x in not_result]\n",
    "                not_result_str = ','.join(not_result)\n",
    "                index_list.append(not_result_str)\n",
    "\n",
    "        index_list_str = \"\\n\".join(index_list)\n",
    "                \n",
    "    # TODO output result\n",
    "        with open(args.output, 'w') as output_file:\n",
    "            output_file.write(index_list_str)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
